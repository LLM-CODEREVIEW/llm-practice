from typing import Dict, List, Any
from loguru import logger
from pr_extractor import PRExtractor
import re

class LineCommenter:
    def __init__(self):
        self.severity_emoji = {
            "HIGH": "ğŸ”´",
            "MEDIUM": "ğŸŸ¡",
            "LOW": "ğŸŸ¢"
        }
        
        self.category_emoji = {
            "BUG": "ğŸ›",
            "PERFORMANCE": "âš¡",
            "READABILITY": "ğŸ“",
            "SECURITY": "ğŸ”’",
            "OTHER": "â„¹ï¸"
        }

    def _parse_review(self, review_text: str) -> List[Dict[str, Any]]:
        """ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì´ìŠˆ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        issues = []

        # LLM ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(review_text, list):
            review_text = '\n'.join(review_text)

        # ì •ê·œì‹ íŒ¨í„´ ê°œì„ 
        line_pattern = r"Line:\s*([\d,\- ]+)"
        severity_pattern = r"Severity:\s*(HIGH|MEDIUM|LOW)"
        category_pattern = r"Category:\s*(BUG|PERFORMANCE|READABILITY|SECURITY|OTHER)"
        description_pattern = r"Description:\s*(.*?)(?=\n\n|$)"
        suggestion_pattern = r"(Proposal|Proposed solution|ì œì•ˆ):\s*(.*?)(?=\n\n|$)"

        # ê° ì´ìŠˆ ë¸”ë¡ ì¶”ì¶œ
        issue_blocks = re.split(r"(?=Line:\s*[\d,\- ]+)", review_text)

        for block in issue_blocks:
            if not block.strip():
                continue

            line_match = re.search(line_pattern, block)
            if not line_match:
                logger.warning(f"[DEBUG] blockì—ì„œ ë¼ì¸ íŒŒì‹± ì‹¤íŒ¨: {block}")
                continue

            # ì—¬ëŸ¬ ë¼ì¸/êµ¬ê°„ íŒŒì‹±
            line_field = line_match.group(1)
            line_nums = []
            for part in line_field.split(','):
                part = part.strip()
                m = re.match(r'^(\d+)-(\d+)$', part)
                if m:
                    start, end = int(m.group(1)), int(m.group(2))
                    line_nums.extend(range(start, end + 1))
                else:
                    m = re.match(r'^(\d+)$', part)
                    if m:
                        line_nums.append(int(m.group(1)))

            severity_match = re.search(severity_pattern, block)
            category_match = re.search(category_pattern, block)
            description_match = re.search(description_pattern, block)
            suggestion_match = re.search(suggestion_pattern, block)

            if severity_match and category_match and description_match:
                for line_num in line_nums:
                    issue = {
                        'line': line_num,
                        'severity': severity_match.group(1),
                        'category': category_match.group(1),
                        'description': description_match.group(1).strip(),
                        'suggestion': suggestion_match.group(2).strip() if suggestion_match else ""
                    }
                    issues.append(issue)

        return issues

    def _format_comment(self, issue: Dict[str, Any], context: Dict[str, Any]) -> str:
        """ì´ìŠˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½”ë©˜íŠ¸ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        severity = self.severity_emoji.get(issue['severity'], "â„¹ï¸")
        category = self.category_emoji.get(issue['category'], "â„¹ï¸")
        
        comment = f"{severity} **{issue['severity']}** {category} **{issue['category']}**\n\n"
        comment += f"{issue['description']}\n\n"
        
        if issue['suggestion']:
            comment += "**ê°œì„  ì œì•ˆ:**\n"
            comment += f"```\n{issue['suggestion']}\n```\n\n"
        
        if context and 'context' in context:
            comment += "**ì»¨í…ìŠ¤íŠ¸:**\n"
            comment += "```\n"
            for i, line in enumerate(context['context'], start=context.get('start_line', 1)):
                comment += f"  {i}: {line}\n"
            comment += "```"
        
        return comment

    def generate_comments(self, review_results: Dict[str, Any], pr_extractor: PRExtractor) -> List[Dict[str, Any]]:
        """ë¦¬ë·° ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¼ì¸ë³„ ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        logger.debug(f"[DEBUG] review_results: {review_results}")
        comments = []
        
        try:
            # review_resultsì—ì„œ reviews ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            reviews = review_results.get('reviews', [])
            
            for review in reviews:
                file_name = review.get('file')
                review_text = review.get('review')
                logger.debug(f"[DEBUG] file_name: {file_name}, review_text: {review_text}")
                
                if not file_name or not review_text:
                    continue
                
                # ë¦¬ë·° í…ìŠ¤íŠ¸ íŒŒì‹±
                issues = self._parse_review(review_text)
                logger.debug(f"[DEBUG] íŒŒì‹±ëœ issues: {issues}")
                
                for issue in issues:
                    # ë¼ì¸ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
                    if not issue.get('line'):
                        continue
                    
                    # íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    context = pr_extractor.get_file_context(file_name, issue['line'])
                    
                    # ì½”ë©˜íŠ¸ ìƒì„±
                    comment = self._format_comment(issue, context)
                    
                    comments.append({
                        'file': file_name,
                        'line': issue['line'],
                        'body': comment,
                        'severity': issue['severity'],
                        'category': issue['category']
                    })
            
            # ì‹¬ê°ë„ì™€ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë ¬
            comments.sort(
                key=lambda x: (
                    {"HIGH": 0, "MEDIUM": 1, "LOW": 2}[x['severity']],
                    x['category']
                )
            )
            
            logger.debug(f"[DEBUG] ìµœì¢… ìƒì„±ëœ comments: {comments}")
            return comments

        except Exception as e:
            logger.error(f"Error generating comments: {str(e)}")
            raise 